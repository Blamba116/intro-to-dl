{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 221
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 15464,
     "status": "ok",
     "timestamp": 1578131854540,
     "user": {
      "displayName": "Ivan Anikin",
      "photoUrl": "",
      "userId": "08904002860838728244"
     },
     "user_tz": -180
    },
    "id": "fn-xHTYx_CF6",
    "outputId": "bd04efc7-7911-4579-8bdb-66e67cf03c98"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shred: setup_google_colab.py: failed to open for writing: No such file or directory\n",
      "--2020-01-04 09:57:22--  https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.0.133, 151.101.64.133, 151.101.128.133, ...\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.0.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 3636 (3.6K) [text/plain]\n",
      "Saving to: ‘setup_google_colab.py’\n",
      "\n",
      "setup_google_colab. 100%[===================>]   3.55K  --.-KB/s    in 0s      \n",
      "\n",
      "2020-01-04 09:57:22 (56.5 MB/s) - ‘setup_google_colab.py’ saved [3636/3636]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "! shred -u setup_google_colab.py\n",
    "! wget https://raw.githubusercontent.com/hse-aml/intro-to-dl/master/setup_google_colab.py -O setup_google_colab.py\n",
    "import setup_google_colab\n",
    "# please, uncomment the week you're working on\n",
    "# setup_google_colab.setup_week1()\n",
    "# setup_google_colab.setup_week2()\n",
    "# setup_google_colab.setup_week2_honor()\n",
    "# setup_google_colab.setup_week3()\n",
    "# setup_google_colab.setup_week4()\n",
    "setup_google_colab.setup_week5()\n",
    "# setup_google_colab.setup_week6()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "5Mc0v-0s_Ak6"
   },
   "outputs": [],
   "source": [
    "# set tf 1.x for colab\n",
    "%tensorflow_version 1.x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "lKSxP7NB_Ak_"
   },
   "source": [
    "# Generating names with recurrent neural networks\n",
    "\n",
    "This time you'll find yourself delving into the heart (and other intestines) of recurrent neural networks on a class of toy problems.\n",
    "\n",
    "Struggle to find a name for the variable? Let's see how you'll come up with a name for your son/daughter. Surely no human has expertize over what is a good child name, so let us train RNN instead;\n",
    "\n",
    "It's dangerous to go alone, take these:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.696201Z",
     "start_time": "2018-08-13T20:26:38.104103Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 51
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 4229,
     "status": "ok",
     "timestamp": 1578132013573,
     "user": {
      "displayName": "Ivan Anikin",
      "photoUrl": "",
      "userId": "08904002860838728244"
     },
     "user_tz": -180
    },
    "id": "egI0uQ6p_AlA",
    "outputId": "edf26aa1-fdc2-4a14-e5a5-7d0ed7e266cf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.15.0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "print(tf.__version__)\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import keras_utils\n",
    "import tqdm_utils"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "WMn1fLXN_AlC"
   },
   "source": [
    "# Load data\n",
    "The dataset contains ~8k earthling names from different cultures, all in latin transcript.\n",
    "\n",
    "This notebook has been designed so as to allow you to quickly swap names for something similar: deep learning article titles, IKEA furniture, pokemon names, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.701832Z",
     "start_time": "2018-08-13T20:26:42.697766Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "pWgYsA2q_AlD"
   },
   "outputs": [],
   "source": [
    "start_token = \" \"  # so that the network knows that we're generating a first token\n",
    "\n",
    "# this is the token for padding,\n",
    "# we will add fake pad token at the end of names \n",
    "# to make them of equal size for further batching\n",
    "pad_token = \"#\"\n",
    "\n",
    "with open(\"names\") as f:\n",
    "    names = f.read()[:-1].split('\\n')\n",
    "    names = [start_token + name for name in names]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.707885Z",
     "start_time": "2018-08-13T20:26:42.703302Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 170
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1127,
     "status": "ok",
     "timestamp": 1578132045326,
     "user": {
      "displayName": "Ivan Anikin",
      "photoUrl": "",
      "userId": "08904002860838728244"
     },
     "user_tz": -180
    },
    "id": "vNTvv5B__AlF",
    "outputId": "cb75e42b-5fb3-4d51-c87e-c7c23fdc0697"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of samples: 7944\n",
      " Abagael\n",
      " Claresta\n",
      " Glory\n",
      " Liliane\n",
      " Prissie\n",
      " Geeta\n",
      " Giovanne\n",
      " Piggy\n"
     ]
    }
   ],
   "source": [
    "print('number of samples:', len(names))\n",
    "for x in names[::1000]:\n",
    "    print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.857411Z",
     "start_time": "2018-08-13T20:26:42.709371Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 298
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1056,
     "status": "ok",
     "timestamp": 1578132068965,
     "user": {
      "displayName": "Ivan Anikin",
      "photoUrl": "",
      "userId": "08904002860838728244"
     },
     "user_tz": -180
    },
    "id": "7u16YGgk_AlH",
    "outputId": "a758e9cf-6bc2-4327-9b71-475134669bbf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max length: 16\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEICAYAAACzliQjAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQ9/MLCMOfTOzjPx/p/4cUF1Gcl0AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "MAX_LENGTH = max(map(len, names))\n",
    "print(\"max length:\", MAX_LENGTH)\n",
    "\n",
    "plt.title('Sequence length distribution')\n",
    "plt.hist(list(map(len, names)), bins=25);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1RIH30It_AlJ"
   },
   "source": [
    "# Text processing\n",
    "\n",
    "First we need to collect a \"vocabulary\" of all unique tokens i.e. unique characters. We can then encode inputs as a sequence of character ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.864592Z",
     "start_time": "2018-08-13T20:26:42.858725Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1589,
     "status": "ok",
     "timestamp": 1578133896320,
     "user": {
      "displayName": "Ivan Anikin",
      "photoUrl": "",
      "userId": "08904002860838728244"
     },
     "user_tz": -180
    },
    "id": "cb_jk1rL_AlK",
    "outputId": "b10ae287-c21e-447c-aa93-c69730935b7f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_tokens: 56\n"
     ]
    }
   ],
   "source": [
    "# tokens = ### YOUR CODE HERE: all unique characters go here, padding included!\n",
    "tokens = np.array(list(map(list, names)))\n",
    "tokens = set(tokens.sum() + [pad_token])\n",
    "\n",
    "tokens = list(tokens)\n",
    "n_tokens = len(tokens)\n",
    "print ('n_tokens:', n_tokens)\n",
    "\n",
    "assert 50 < n_tokens < 60"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YmNVeu4K_AlM"
   },
   "source": [
    "### Cast everything from symbols into identifiers\n",
    "\n",
    "Tensorflow string manipulation is a bit tricky, so we'll work around it. \n",
    "We'll feed our recurrent neural network with ids of characters from our dictionary.\n",
    "\n",
    "To create such dictionary, let's assign `token_to_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.870330Z",
     "start_time": "2018-08-13T20:26:42.866135Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "6TDahdMX_AlM"
   },
   "outputs": [],
   "source": [
    "# token_to_id = ### YOUR CODE HERE: create a dictionary of {symbol -> its  index in tokens}\n",
    "token_to_id = dict(enumerate(tokens))\n",
    "token_to_id = {v:k for k, v in token_to_id.items()}\n",
    "\n",
    "assert len(tokens) == len(token_to_id), \"dictionaries must have same size\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.875943Z",
     "start_time": "2018-08-13T20:26:42.871834Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "HtGN10a6_AlP"
   },
   "outputs": [],
   "source": [
    "def to_matrix(names, max_len=None, pad=token_to_id[pad_token], dtype=np.int32):\n",
    "    \"\"\"Casts a list of names into rnn-digestable padded matrix\"\"\"\n",
    "    \n",
    "    max_len = max_len or max(map(len, names))\n",
    "    names_ix = np.zeros([len(names), max_len], dtype) + pad\n",
    "\n",
    "    for i in range(len(names)):\n",
    "        name_ix = list(map(token_to_id.get, names[i]))\n",
    "        names_ix[i, :len(name_ix)] = name_ix\n",
    "\n",
    "    return names_ix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:42.883107Z",
     "start_time": "2018-08-13T20:26:42.877186Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 153
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 762,
     "status": "ok",
     "timestamp": 1578133908613,
     "user": {
      "displayName": "Ivan Anikin",
      "photoUrl": "",
      "userId": "08904002860838728244"
     },
     "user_tz": -180
    },
    "id": "VCQhN7PA_AlR",
    "outputId": "92a70f8c-6ff5-4e30-910d-e9e7ea032ab3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Abagael\n",
      " Glory\n",
      " Prissie\n",
      " Giovanne\n",
      "[[10 23 49 32 16 32 54 35  9]\n",
      " [10 53 35  0  6 17  9  9  9]\n",
      " [10 46  6 51 38 38 51 54  9]\n",
      " [10 53 51  0 24 32 45 45 54]]\n"
     ]
    }
   ],
   "source": [
    "# Example: cast 4 random names to padded matrices (so that we can easily batch them)\n",
    "print('\\n'.join(names[::2000]))\n",
    "print(to_matrix(names[::2000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "C6QGJv7e_AlS"
   },
   "source": [
    "# Defining a recurrent neural network\n",
    "\n",
    "We can rewrite recurrent neural network as a consecutive application of dense layer to input $x_t$ and previous rnn state $h_t$. This is exactly what we're gonna do now.\n",
    "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week5/rnn.png?raw=1\" width=600>\n",
    "\n",
    "Since we're training a language model, there should also be:\n",
    "* An embedding layer that converts character id x_t to a vector.\n",
    "* An output layer that predicts probabilities of next phoneme based on h_t+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.039419Z",
     "start_time": "2018-08-13T20:26:42.884581Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "TkEmOSMV_AlT"
   },
   "outputs": [],
   "source": [
    "# remember to reset your session if you change your graph!\n",
    "s = keras_utils.reset_tf_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.044903Z",
     "start_time": "2018-08-13T20:26:44.041084Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "ywhO5hxQ_AlV"
   },
   "outputs": [],
   "source": [
    "import keras\n",
    "from keras.layers import concatenate, Dense, Embedding\n",
    "\n",
    "rnn_num_units = 64  # size of hidden state\n",
    "embedding_size = 16  # for characters\n",
    "\n",
    "# Let's create layers for our recurrent network\n",
    "# Note: we create layers but we don't \"apply\" them yet (this is a \"functional API\" of Keras)\n",
    "# Note: set the correct activation (from keras.activations) to Dense layers!\n",
    "\n",
    "# an embedding layer that converts character ids into embeddings\n",
    "embed_x = Embedding(n_tokens, embedding_size)\n",
    "\n",
    "# a dense layer that maps input and previous state to new hidden state, [x_t,h_t]->h_t+1\n",
    "get_h_next = Dense(rnn_num_units, activation='tanh')\n",
    "\n",
    "# a dense layer that maps current hidden state to probabilities of characters [h_t+1]->P(x_t+1|h_t+1)\n",
    "get_probas = Dense(n_tokens, activation='softmax')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "kxZkMwrt_AlX"
   },
   "source": [
    "We will generate names character by character starting with `start_token`:\n",
    "\n",
    "<img src=\"https://github.com/hse-aml/intro-to-dl/blob/master/week5/char-nn.png?raw=1\" width=600>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.053212Z",
     "start_time": "2018-08-13T20:26:44.048389Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "4sktKAW__AlY"
   },
   "outputs": [],
   "source": [
    "def rnn_one_step(x_t, h_t):\n",
    "    \"\"\"\n",
    "    Recurrent neural network step that produces \n",
    "    probabilities for next token x_t+1 and next state h_t+1\n",
    "    given current input x_t and previous state h_t.\n",
    "    We'll call this method repeatedly to produce the whole sequence.\n",
    "    \n",
    "    You're supposed to \"apply\" above layers to produce new tensors.\n",
    "    Follow inline instructions to complete the function.\n",
    "    \"\"\"\n",
    "    # convert character id into embedding\n",
    "    x_t_emb = embed_x(tf.reshape(x_t, [-1, 1]))[:, 0]\n",
    "    \n",
    "    # concatenate x_t embedding and previous h_t state\n",
    "    x_and_h = concatenate([x_t_emb, h_t], axis=-1)\n",
    "    \n",
    "    # compute next state given x_and_h\n",
    "    h_next = get_h_next(x_and_h)\n",
    "    \n",
    "    # get probabilities for language model P(x_next|h_next)\n",
    "    output_probas = get_probas(h_next)\n",
    "    \n",
    "    return output_probas, h_next"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "pmd3hOu4_Ala"
   },
   "source": [
    "# RNN: loop\n",
    "\n",
    "Once `rnn_one_step` is ready, let's apply it in a loop over name characters to get predictions.\n",
    "\n",
    "Let's assume that all names are at most length-16 for now, so we can simply iterate over them in a for loop.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.342948Z",
     "start_time": "2018-08-13T20:26:44.056136Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "LV5ONJ6c_Ala"
   },
   "outputs": [],
   "source": [
    "input_sequence = tf.placeholder(tf.int32, (None, MAX_LENGTH))  # batch of token ids\n",
    "batch_size = tf.shape(input_sequence)[0]\n",
    "\n",
    "predicted_probas = []\n",
    "h_prev = tf.zeros([batch_size, rnn_num_units])  # initial hidden state\n",
    "\n",
    "for t in range(MAX_LENGTH):\n",
    "    x_t = input_sequence[:, t]  # column t\n",
    "    probas_next, h_next = rnn_one_step(x_t, h_prev)\n",
    "    \n",
    "    h_prev = h_next\n",
    "    predicted_probas.append(probas_next)\n",
    "    \n",
    "# combine predicted_probas into [batch, time, n_tokens] tensor\n",
    "predicted_probas = tf.transpose(tf.stack(predicted_probas), [1, 0, 2])\n",
    "\n",
    "# next to last token prediction is not needed\n",
    "predicted_probas = predicted_probas[:, :-1, :]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "LA48fbC-_Alc"
   },
   "source": [
    "# RNN: loss and gradients\n",
    "\n",
    "Let's gather a matrix of predictions for $P(x_{next}|h)$ and the corresponding correct answers.\n",
    "\n",
    "We will flatten our matrices to shape [None, n_tokens] to make it easier.\n",
    "\n",
    "Our network can then be trained by minimizing crossentropy between predicted probabilities and those answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:44.354310Z",
     "start_time": "2018-08-13T20:26:44.344648Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "7vl6oiSY_Ald"
   },
   "outputs": [],
   "source": [
    "# flatten predictions to [batch*time, n_tokens]\n",
    "predictions_matrix = tf.reshape(predicted_probas, [-1, n_tokens])\n",
    "\n",
    "# flatten answers (next tokens) and one-hot encode them\n",
    "answers_matrix = tf.one_hot(tf.reshape(input_sequence[:, 1:], [-1]), n_tokens)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7dy3ohIo_Alf"
   },
   "source": [
    "Usually it's a good idea to ignore gradients of loss for padding token predictions.\n",
    "\n",
    "Because we don't care about further prediction after the pad_token is predicted for the first time, so it doesn't make sense to punish our network after the pad_token is predicted.\n",
    "\n",
    "For simplicity you can ignore this comment, it's up to you."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:45.076642Z",
     "start_time": "2018-08-13T20:26:44.355594Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 173
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1394,
     "status": "ok",
     "timestamp": 1578134776111,
     "user": {
      "displayName": "Ivan Anikin",
      "photoUrl": "",
      "userId": "08904002860838728244"
     },
     "user_tz": -180
    },
    "id": "lXLVD9di_Alg",
    "outputId": "1c3134e9-7894-42f3-b434-c00d496f96fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2745: calling reduce_sum_v1 (from tensorflow.python.ops.math_ops) with keep_dims is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "keep_dims is deprecated, use keepdims instead\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:2749: The name tf.log is deprecated. Please use tf.math.log instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    }
   ],
   "source": [
    "# Define the loss as categorical cross-entropy (e.g. from keras.losses).\n",
    "# Mind that predictions are probabilities and NOT logits!\n",
    "# Remember to apply tf.reduce_mean to get a scalar loss!\n",
    "loss = tf.reduce_mean(keras.losses.categorical_crossentropy(answers_matrix, predictions_matrix))\n",
    "\n",
    "optimize = tf.train.AdamOptimizer().minimize(loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "-1hO80_X_Ali"
   },
   "source": [
    "# RNN: training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:55.322187Z",
     "start_time": "2018-08-13T20:26:45.078296Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 265
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 6,
     "status": "ok",
     "timestamp": 1578134799854,
     "user": {
      "displayName": "Ivan Anikin",
      "photoUrl": "",
      "userId": "08904002860838728244"
     },
     "user_tz": -180
    },
    "id": "mOZI8t8Y_Ali",
    "outputId": "135c01a2-a277-443f-926b-3050188a6a6c"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXQAAAD4CAYAAAD8Zh1EAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nhAZ0pZSKEf8POlxjusesbbYAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import clear_output\n",
    "from random import sample\n",
    "\n",
    "s.run(tf.global_variables_initializer())\n",
    "\n",
    "batch_size = 32\n",
    "history = []\n",
    "\n",
    "for i in range(1000):\n",
    "    batch = to_matrix(sample(names, batch_size), max_len=MAX_LENGTH)\n",
    "    loss_i, _ = s.run([loss, optimize], {input_sequence: batch})\n",
    "    \n",
    "    history.append(loss_i)\n",
    "    \n",
    "    if (i + 1) % 100 == 0:\n",
    "        clear_output(True)\n",
    "        plt.plot(history, label='loss')\n",
    "        plt.legend()\n",
    "        plt.show()\n",
    "\n",
    "assert np.mean(history[:10]) > np.mean(history[-10:]), \"RNN didn't converge\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ND-7ovTw_Alm"
   },
   "source": [
    "# RNN: sampling\n",
    "Once we've trained our network a bit, let's get to actually generating stuff. All we need is the `rnn_one_step` function you have written above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:55.341196Z",
     "start_time": "2018-08-13T20:26:55.323787Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "KkngakYV_Aln"
   },
   "outputs": [],
   "source": [
    "x_t = tf.placeholder(tf.int32, (1,))\n",
    "h_t = tf.Variable(np.zeros([1, rnn_num_units], np.float32))  # we will update hidden state in this variable\n",
    "\n",
    "# For sampling we need to define `rnn_one_step` tensors only once in our graph.\n",
    "# We reuse all parameters thanks to functional API usage.\n",
    "# Then we can feed appropriate tensor values using feed_dict in a loop.\n",
    "# Note how different it is from training stage, where we had to unroll the whole sequence for backprop.\n",
    "next_probs, next_h = rnn_one_step(x_t, h_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:55.346422Z",
     "start_time": "2018-08-13T20:26:55.342659Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "K8Ggoehy_Alr"
   },
   "outputs": [],
   "source": [
    "def generate_sample(seed_phrase=start_token, max_length=MAX_LENGTH):\n",
    "    '''\n",
    "    This function generates text given a `seed_phrase` as a seed.\n",
    "    Remember to include start_token in seed phrase!\n",
    "    Parameter `max_length` is used to set the number of characters in prediction.\n",
    "    '''\n",
    "    x_sequence = [token_to_id[token] for token in seed_phrase]\n",
    "    s.run(tf.assign(h_t, h_t.initial_value))\n",
    "    \n",
    "    # feed the seed phrase, if any\n",
    "    for ix in x_sequence[:-1]:\n",
    "         s.run(tf.assign(h_t, next_h), {x_t: [ix]})\n",
    "    \n",
    "    # start generating\n",
    "    for _ in range(max_length-len(seed_phrase)):\n",
    "        x_probs,_ = s.run([next_probs, tf.assign(h_t, next_h)], {x_t: [x_sequence[-1]]})\n",
    "        x_sequence.append(np.random.choice(n_tokens, p=x_probs[0]))\n",
    "        \n",
    "    return ''.join([tokens[ix] for ix in x_sequence if tokens[ix] != pad_token])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:26:58.458115Z",
     "start_time": "2018-08-13T20:26:55.347900Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3915,
     "status": "ok",
     "timestamp": 1578134926758,
     "user": {
      "displayName": "Ivan Anikin",
      "photoUrl": "",
      "userId": "08904002860838728244"
     },
     "user_tz": -180
    },
    "id": "oYmlpAIp_Alt",
    "outputId": "9a81d777-44ee-4f4d-8640-5cfd7888eb70"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Seinnan\n",
      " Ketsy\n",
      " Peene\n",
      " Race\n",
      " Honde\n",
      " Falnyne\n",
      " Myys\n",
      " Inetdent\n",
      " Brrriint\n",
      " Hicmin\n"
     ]
    }
   ],
   "source": [
    "# without prefix\n",
    "for _ in range(10):\n",
    "    print(generate_sample())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:01.986726Z",
     "start_time": "2018-08-13T20:26:58.459810Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 187
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 3886,
     "status": "ok",
     "timestamp": 1578134933041,
     "user": {
      "displayName": "Ivan Anikin",
      "photoUrl": "",
      "userId": "08904002860838728244"
     },
     "user_tz": -180
    },
    "id": "vhiNfDkr_Alw",
    "outputId": "cbfe7231-cdba-479e-8b19-8b561f449e51"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Trumpa\n",
      " Trumpa\n",
      " Trumpani\n",
      " Trumpyr\n",
      " Trumpe\n",
      " Trumpa\n",
      " Trump\n",
      " Trumpie\n",
      " Trumpante\n",
      " Trumpla\n"
     ]
    }
   ],
   "source": [
    "# with prefix conditioning\n",
    "for _ in range(10):\n",
    "    print(generate_sample(' Trump'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "7C8zDLxh_Alx"
   },
   "source": [
    "# Submit to Coursera"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:40:02.004926Z",
     "start_time": "2018-08-13T20:40:02.000821Z"
    },
    "colab": {},
    "colab_type": "code",
    "id": "ayaL9T2P_Aly"
   },
   "outputs": [],
   "source": [
    "# token expires every 30 min\n",
    "COURSERA_TOKEN = 'token'\n",
    "COURSERA_EMAIL = 'login'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:40:18.923357Z",
     "start_time": "2018-08-13T20:40:03.549343Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10271,
     "status": "ok",
     "timestamp": 1578135102178,
     "user": {
      "displayName": "Ivan Anikin",
      "photoUrl": "",
      "userId": "08904002860838728244"
     },
     "user_tz": -180
    },
    "id": "SXY9WU_f_Al0",
    "outputId": "7c6f540c-7490-486a-9684-62c956adcabc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*************************\n",
      "\n",
      "Submitted to Coursera platform. See results on assignment page!\n"
     ]
    }
   ],
   "source": [
    "from submit import submit_char_rnn\n",
    "samples = [generate_sample(' Al') for i in tqdm_utils.tqdm_notebook_failsafe(range(25))]\n",
    "submission = (history, samples)\n",
    "submit_char_rnn(submission, COURSERA_EMAIL, COURSERA_TOKEN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "y3-Y7AeQ_Al2"
   },
   "source": [
    "# Try it out!\n",
    "\n",
    "__Disclaimer:__ This part of assignment is entirely optional. You won't receive bonus points for it. However, it's a fun thing to do. Please share your results on course forums.\n",
    "\n",
    "You've just implemented a recurrent language model that can be tasked with generating any kind of sequence, so there's plenty of data you can try it on:\n",
    "\n",
    "* Novels/poems/songs of your favorite author\n",
    "* News titles/clickbait titles\n",
    "* Source code of Linux or Tensorflow\n",
    "* Molecules in [smiles](https://en.wikipedia.org/wiki/Simplified_molecular-input_line-entry_system) format\n",
    "* Melody in notes/chords format\n",
    "* IKEA catalog titles\n",
    "* Pokemon names\n",
    "* Cards from Magic, the Gathering / Hearthstone\n",
    "\n",
    "If you're willing to give it a try, here's what you wanna look at:\n",
    "* Current data format is a sequence of lines, so a novel can be formatted as a list of sentences. Alternatively, you can change data preprocessing altogether.\n",
    "* While some datasets are readily available, others can only be scraped from the web. Try `Selenium` or `Scrapy` for that.\n",
    "* Make sure MAX_LENGTH is adjusted for longer datasets. There's also a bonus section about dynamic RNNs at the bottom.\n",
    "* More complex tasks require larger RNN architecture, try more neurons or several layers. It would also require more training iterations.\n",
    "* Long-term dependencies in music, novels or molecules are better handled with LSTM or GRU\n",
    "\n",
    "__Good hunting!__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "YSAyBJhj_Al3"
   },
   "source": [
    "# Bonus level: dynamic RNNs\n",
    "\n",
    "Apart from Keras, there's also a friendly TensorFlow API for recurrent neural nets. It's based around the symbolic loop function (aka [tf.scan](https://www.tensorflow.org/api_docs/python/tf/scan)).\n",
    "\n",
    "RNN loop that we implemented for training can be replaced with single TensorFlow instruction: [tf.nn.dynamic_rnn](https://www.tensorflow.org/api_docs/python/tf/nn/dynamic_rnn).\n",
    "This interface allows for dynamic sequence length and comes with some pre-implemented architectures.\n",
    "\n",
    "Take a look at [tf.nn.rnn_cell.BasicRNNCell](https://www.tensorflow.org/api_docs/python/tf/contrib/rnn/BasicRNNCell)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:12.975354Z",
     "start_time": "2018-08-13T20:27:12.737529Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 241
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 10453,
     "status": "ok",
     "timestamp": 1578135344772,
     "user": {
      "displayName": "Ivan Anikin",
      "photoUrl": "",
      "userId": "08904002860838728244"
     },
     "user_tz": -180
    },
    "id": "ANHrNKxl_Al3",
    "outputId": "8f16c461-3828-4df4-d2bc-36d110bde271"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:456: Layer.add_variable (from tensorflow.python.keras.engine.base_layer) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.add_weight` method instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py:460: calling Zeros.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.sparse_tensor_to_dense is deprecated. Please use tf.sparse.to_dense instead.\n",
      "\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/autograph/converters/directives.py:119: The name tf.sparse_tensor_dense_matmul is deprecated. Please use tf.sparse.sparse_dense_matmul instead.\n",
      "\n",
      "LSTM outputs for each step [batch,time,n_tokens]:\n",
      "(10, 50, 56)\n"
     ]
    }
   ],
   "source": [
    "class CustomRNN(tf.nn.rnn_cell.BasicRNNCell):\n",
    "    def call(self, input, state):\n",
    "        # from docs:\n",
    "        # Returns:\n",
    "        # Output: A 2-D tensor with shape [batch_size, self.output_size].\n",
    "        # New state: Either a single 2-D tensor, or a tuple of tensors matching the arity and shapes of state.\n",
    "        return rnn_one_step(input[:, 0], state)\n",
    "    \n",
    "    @property\n",
    "    def output_size(self):\n",
    "        return n_tokens\n",
    "    \n",
    "cell = CustomRNN(rnn_num_units)\n",
    "\n",
    "input_sequence = tf.placeholder(tf.float32, (None, None))\n",
    "    \n",
    "predicted_probas, last_state = tf.nn.dynamic_rnn(cell, input_sequence[:, :, None], dtype=tf.float32)\n",
    "\n",
    "print('LSTM outputs for each step [batch,time,n_tokens]:')\n",
    "print(predicted_probas.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "TY1y3_P4_Al5"
   },
   "source": [
    "Note that we never used MAX_LENGTH in the code above: TF will iterate over however many time-steps you gave it.\n",
    "\n",
    "You can also use any pre-implemented RNN cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:12.981697Z",
     "start_time": "2018-08-13T20:27:12.977590Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 54
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1902,
     "status": "ok",
     "timestamp": 1578135359420,
     "user": {
      "displayName": "Ivan Anikin",
      "photoUrl": "",
      "userId": "08904002860838728244"
     },
     "user_tz": -180
    },
    "id": "SGjyVn-F_Al6",
    "outputId": "6e29f252-6432-403a-ad97-792431748045"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BasicLSTMCell\tBasicRNNCell\tGRUCell\tLSTMCell\tMultiRNNCell\tRNNCell\tBasicLSTMCell\tBasicRNNCell\tBidirectionalGridLSTMCell\tConv1DLSTMCell\tConv2DLSTMCell\tConv3DLSTMCell\tConvLSTMCell\tCoupledInputForgetGateLSTMCell\tFusedRNNCell\tGLSTMCell\tGRUBlockCell\tGRUCell\tGridLSTMCell\tIndRNNCell\tIndyGRUCell\tIndyLSTMCell\tIntersectionRNNCell\tLSTMBlockCell\tLSTMBlockFusedCell\tLSTMCell\tLayerNormBasicLSTMCell\tLayerRNNCell\tMultiRNNCell\tNASCell\tPhasedLSTMCell\tRNNCell\tSRUCell\tTimeFreqLSTMCell\tUGRNNCell\t"
     ]
    }
   ],
   "source": [
    "for obj in dir(tf.nn.rnn_cell) + dir(tf.contrib.rnn):\n",
    "    if obj.endswith('Cell'):\n",
    "        print(obj, end=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-08-13T20:27:13.168207Z",
     "start_time": "2018-08-13T20:27:12.986884Z"
    },
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 476
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 215887,
     "status": "error",
     "timestamp": 1578135598099,
     "user": {
      "displayName": "Ivan Anikin",
      "photoUrl": "",
      "userId": "08904002860838728244"
     },
     "user_tz": -180
    },
    "id": "ZLQQqSMv_Al7",
    "outputId": "d342b2be-0f9f-4440-f022-5f2cf1db1152"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From <ipython-input-78-62766a2145fb>:6: LSTMCell.__init__ (from tensorflow.python.ops.rnn_cell_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This class is equivalent as tf.keras.layers.LSTMCell, and will be replaced by that in Tensorflow 2.0.\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "ignored",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mBuildLoop\u001b[0;34m(self, pred, body, loop_vars, shape_invariants, return_same_structure)\u001b[0m\n\u001b[1;32m   2244\u001b[0m         original_body_result, exit_vars = self._BuildLoop(\n\u001b[0;32m-> 2245\u001b[0;31m             pred, body, original_loop_vars, loop_vars, shape_invariants)\n\u001b[0m\u001b[1;32m   2246\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m_BuildLoop\u001b[0;34m(self, pred, body, original_loop_vars, loop_vars, shape_invariants)\u001b[0m\n\u001b[1;32m   2169\u001b[0m     \u001b[0mpre_summaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2170\u001b[0;31m     \u001b[0mbody_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbody\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mpacked_vars_for_body\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2171\u001b[0m     \u001b[0mpost_summaries\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SUMMARY_COLLECTION\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m(i, lv)\u001b[0m\n\u001b[1;32m   2704\u001b[0m             math_ops.logical_and(i < maximum_iterations, orig_cond(*lv)))\n\u001b[0;32m-> 2705\u001b[0;31m         \u001b[0mbody\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlv\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mi\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morig_body\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mlv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2706\u001b[0m       \u001b[0mtry_to_pack\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn.py\u001b[0m in \u001b[0;36m_time_step\u001b[0;34m(time, output_ta_t, state)\u001b[0m\n\u001b[1;32m    883\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 884\u001b[0;31m       \u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_state\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcall_cell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    885\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn.py\u001b[0m in \u001b[0;36m<lambda>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    869\u001b[0m       \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 870\u001b[0;31m     \u001b[0mcall_cell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mlambda\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minput_t\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    871\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn_cell_impl.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, state, scope, *args, **kwargs)\u001b[0m\n\u001b[1;32m    385\u001b[0m     return base_layer.Layer.__call__(\n\u001b[0;32m--> 386\u001b[0;31m         self, inputs, state, scope=scope, *args, **kwargs)\n\u001b[0m\u001b[1;32m    387\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/layers/base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    547\u001b[0m       \u001b[0;31m# Actually call layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 548\u001b[0;31m       \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLayer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    549\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs, *args, **kwargs)\u001b[0m\n\u001b[1;32m    801\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mbuild_graph\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mbase_layer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mneeds_keras_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 802\u001b[0;31m       \u001b[0mbase_layer_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_keras_history\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    803\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36mcreate_keras_history\u001b[0;34m(tensors)\u001b[0m\n\u001b[1;32m    183\u001b[0m   \"\"\"\n\u001b[0;32m--> 184\u001b[0;31m   \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreated_layers\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_create_keras_history_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    185\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mcreated_layers\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36m_create_keras_history_helper\u001b[0;34m(tensors, processed_ops, created_layers)\u001b[0m\n\u001b[1;32m    230\u001b[0m       processed_ops, created_layers = _create_keras_history_helper(\n\u001b[0;32m--> 231\u001b[0;31m           layer_inputs, processed_ops, created_layers)\n\u001b[0m\u001b[1;32m    232\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36m_create_keras_history_helper\u001b[0;34m(tensors, processed_ops, created_layers)\u001b[0m\n\u001b[1;32m    230\u001b[0m       processed_ops, created_layers = _create_keras_history_helper(\n\u001b[0;32m--> 231\u001b[0;31m           layer_inputs, processed_ops, created_layers)\n\u001b[0m\u001b[1;32m    232\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36m_create_keras_history_helper\u001b[0;34m(tensors, processed_ops, created_layers)\u001b[0m\n\u001b[1;32m    230\u001b[0m       processed_ops, created_layers = _create_keras_history_helper(\n\u001b[0;32m--> 231\u001b[0;31m           layer_inputs, processed_ops, created_layers)\n\u001b[0m\u001b[1;32m    232\u001b[0m       \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mop\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/engine/base_layer_utils.py\u001b[0m in \u001b[0;36m_create_keras_history_helper\u001b[0;34m(tensors, processed_ops, created_layers)\u001b[0m\n\u001b[1;32m    228\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit_scope\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 229\u001b[0;31m               \u001b[0mconstants\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbackend\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mop_input\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    230\u001b[0m       processed_ops, created_layers = _create_keras_history_helper(\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   3440\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3441\u001b[0;31m     \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   3442\u001b[0m     \u001b[0mfeed_arrays\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36mget_session\u001b[0;34m(op_input_list)\u001b[0m\n\u001b[1;32m    485\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_default\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 486\u001b[0;31m       \u001b[0m_initialize_variables\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    487\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0msession\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/keras/backend.py\u001b[0m in \u001b[0;36m_initialize_variables\u001b[0;34m(session)\u001b[0m\n\u001b[1;32m    902\u001b[0m     is_initialized = session.run(\n\u001b[0;32m--> 903\u001b[0;31m         [variables_module.is_variable_initialized(v) for v in candidate_vars])\n\u001b[0m\u001b[1;32m    904\u001b[0m     \u001b[0muninitialized_vars\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    955\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 956\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    957\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1179\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1180\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1181\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1358\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1359\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1360\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1364\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1365\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1366\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1347\u001b[0m       \u001b[0;31m# Ensure any changes to the graph are reflected in the runtime.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1348\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1349\u001b[0m       return self._call_tf_sessionrun(options, feed_dict, fetch_list,\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/client/session.py\u001b[0m in \u001b[0;36m_extend_graph\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1386\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1387\u001b[0;31m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_graph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session_run_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1388\u001b[0m       \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExtendSession\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/lock_util.py\u001b[0m in \u001b[0;36m__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    123\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__enter__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 124\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_group_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    125\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/lock_util.py\u001b[0m in \u001b[0;36macquire\u001b[0;34m(self, group_id)\u001b[0m\n\u001b[1;32m     91\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_another_group_active\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 92\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwait\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     93\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_group_member_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgroup_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.6/threading.py\u001b[0m in \u001b[0;36mwait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    294\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mtimeout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m                 \u001b[0mwaiter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m                 \u001b[0mgotit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: ",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-62766a2145fb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mcell\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrnn_cell\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLSTMCell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrnn_num_units\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mstate_sequence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdynamic_rnn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs_embedded\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0ms\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mglobal_variables_initializer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/deprecation.py\u001b[0m in \u001b[0;36mnew_func\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    322\u001b[0m               \u001b[0;34m'in a future version'\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mdate\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m'after %s'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mdate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    323\u001b[0m               instructions)\n\u001b[0;32m--> 324\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    325\u001b[0m     return tf_decorator.make_decorator(\n\u001b[1;32m    326\u001b[0m         \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnew_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'deprecated'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn.py\u001b[0m in \u001b[0;36mdynamic_rnn\u001b[0;34m(cell, inputs, sequence_length, initial_state, dtype, parallel_iterations, swap_memory, time_major, scope)\u001b[0m\n\u001b[1;32m    705\u001b[0m         \u001b[0mswap_memory\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswap_memory\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    706\u001b[0m         \u001b[0msequence_length\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msequence_length\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 707\u001b[0;31m         dtype=dtype)\n\u001b[0m\u001b[1;32m    708\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    709\u001b[0m     \u001b[0;31m# Outputs of _dynamic_rnn_loop are always shaped [time, batch, depth].\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/rnn.py\u001b[0m in \u001b[0;36m_dynamic_rnn_loop\u001b[0;34m(cell, inputs, initial_state, parallel_iterations, swap_memory, sequence_length, dtype)\u001b[0m\n\u001b[1;32m    914\u001b[0m       \u001b[0mparallel_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparallel_iterations\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    915\u001b[0m       \u001b[0mmaximum_iterations\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtime_steps\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 916\u001b[0;31m       swap_memory=swap_memory)\n\u001b[0m\u001b[1;32m    917\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    918\u001b[0m   \u001b[0;31m# Unpack final output if not using output tuples.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mwhile_loop\u001b[0;34m(cond, body, loop_vars, shape_invariants, parallel_iterations, back_prop, swap_memory, name, maximum_iterations, return_same_structure)\u001b[0m\n\u001b[1;32m   2751\u001b[0m       \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_to_collection\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mGraphKeys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mWHILE_CONTEXT\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloop_context\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2752\u001b[0m     result = loop_context.BuildLoop(cond, body, loop_vars, shape_invariants,\n\u001b[0;32m-> 2753\u001b[0;31m                                     return_same_structure)\n\u001b[0m\u001b[1;32m   2754\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mmaximum_iterations\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2755\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/control_flow_ops.py\u001b[0m in \u001b[0;36mBuildLoop\u001b[0;34m(self, pred, body, loop_vars, shape_invariants, return_same_structure)\u001b[0m\n\u001b[1;32m   2243\u001b[0m       \u001b[0;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_default_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_mutation_lock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2244\u001b[0m         original_body_result, exit_vars = self._BuildLoop(\n\u001b[0;32m-> 2245\u001b[0;31m             pred, body, original_loop_vars, loop_vars, shape_invariants)\n\u001b[0m\u001b[1;32m   2246\u001b[0m     \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2247\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/lock_util.py\u001b[0m in \u001b[0;36m__exit__\u001b[0;34m(***failed resolving arguments***)\u001b[0m\n\u001b[1;32m    126\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__exit__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_arg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_arg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback_arg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    127\u001b[0m       \u001b[0;32mdel\u001b[0m \u001b[0mtype_arg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalue_arg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraceback_arg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 128\u001b[0;31m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrelease\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_group_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow_core/python/util/lock_util.py\u001b[0m in \u001b[0;36mrelease\u001b[0;34m(self, group_id)\u001b[0m\n\u001b[1;32m     98\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_validate_group_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup_id\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_ready\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_group_member_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgroup_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_group_member_counts\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mgroup_id\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "input_sequence = tf.placeholder(tf.int32, (None, None))\n",
    "\n",
    "inputs_embedded = embed_x(input_sequence)\n",
    "\n",
    "# standard cell returns hidden state as output!\n",
    "cell = tf.nn.rnn_cell.LSTMCell(rnn_num_units)\n",
    "\n",
    "state_sequence, last_state = tf.nn.dynamic_rnn(cell, inputs_embedded, dtype=tf.float32)\n",
    "\n",
    "s.run(tf.global_variables_initializer())\n",
    "\n",
    "print('LSTM hidden state for each step [batch,time,rnn_num_units]:')\n",
    "print(state_sequence.eval({input_sequence: to_matrix(names[:10], max_len=50)}).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "hdxzdaiDMuhE"
   },
   "outputs": [],
   "source": [
    "! pkill -9 python3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YghEaUgENkSY"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "Copy of RNN-task.ipynb",
   "provenance": [
    {
     "file_id": "https://github.com/hse-aml/intro-to-dl/blob/master/week5/RNN-task.ipynb",
     "timestamp": 1578131815113
    }
   ]
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
